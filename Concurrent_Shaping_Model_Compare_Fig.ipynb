{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2umqLM1Y5wd9",
      "metadata": {
        "id": "2umqLM1Y5wd9"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "This colab contains code used to run the ridgeplot visualization for the Concurrent Trait Shaping experiments on the various LLMs experimented on in the paper \"Personality Traits in Large Language Models\" (https://arxiv.org/pdf/2307.00184). The code requires \"scored\" output of the LLM inference dataframes - which are themselves the output of the Concurrent Trait Shaping Analysis notebook. The code assumes that all the data produced and consumed in the colab lives in a local filesystem either in a cloud instance running a Jupyter notebook such as Google Colab or a desktop. But those file I/O operations can easily be replaced to use any other file management solutions.\n",
        "\n",
        "To run this colab:\n",
        "1. Connect to an appropriate runtime. (For instance, if running the bulk inference directly from the colab, connect to a GPU kernel.)\n",
        "2. Check experiment parameters below.\n",
        "3. Run the code cells for generating the ridge plot visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7781c8",
      "metadata": {
        "id": "9c7781c8"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pW61sWAP6dhQ",
      "metadata": {
        "id": "pW61sWAP6dhQ"
      },
      "outputs": [],
      "source": [
        "#@title Install visualization dependencies\n",
        "%pip install plotly\n",
        "%pip install matplotlib\n",
        "%pip install pandas\n",
        "%pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad809ffe",
      "metadata": {
        "id": "ad809ffe"
      },
      "outputs": [],
      "source": [
        "#@title Load Dependencies\n",
        "from typing import List, OrderedDict, Union\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afcf46d8",
      "metadata": {
        "id": "afcf46d8"
      },
      "outputs": [],
      "source": [
        "SPID = ['item_preamble_id',\n",
        "        'item_postamble_id',\n",
        "        'response_scale_id',\n",
        "        'response_choice_postamble_id',\n",
        "        'model_id']\n",
        "\n",
        "BFI_SCALE_IDS = ['BFI-EXT', 'BFI-AGR', 'BFI-CON', 'BFI-NEU', 'BFI-OPE']\n",
        "IPIP_SCALE_IDS = ['IPIP300-EXT', 'IPIP300-AGR', 'IPIP300-CON', 'IPIP300-NEU', 'IPIP300-OPE']\n",
        "VALIDATION_SCALE_IDS = ['PA', 'NA', 'CSE', 'CPI', 'PHYS', 'VRBL', 'ANGR', 'HSTL', 'ACHV', 'CONF', 'SCRT']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caz5fIVr-5Di",
      "metadata": {
        "id": "caz5fIVr-5Di"
      },
      "source": [
        "# Ridgeplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V609YWqGKJ55",
      "metadata": {
        "id": "V609YWqGKJ55"
      },
      "outputs": [],
      "source": [
        "#@title Helper Functions\n",
        "def get_domain_fragments(big5_id):\n",
        "  \"\"\"Returns list of preamble ID fragments for one domain.\"\"\"\n",
        "  return [f'{big5_id}{i}' for i in range(1, 10)]\n",
        "\n",
        "\n",
        "DIMENSION_PREFIXES = ['ext', 'agr', 'con', 'neu', 'ope']\n",
        "\n",
        "def get_big5_lvl_fragments():\n",
        "  \"\"\"Returns list of preamble ID fragments for all Big Five domains.\"\"\"\n",
        "  big5_id_fragments = DIMENSION_PREFIXES\n",
        "  nested_fragments = [get_domain_fragments(big5_id) for big5_id in big5_id_fragments]\n",
        "  preamble_id_fragments = list(itertools.chain(*nested_fragments))\n",
        "  return preamble_id_fragments\n",
        "\n",
        "\n",
        "def subset_one_preamble(input_df, id_fragment):\n",
        "  return input_df[input_df['item_preamble_id'].str.contains(id_fragment)][IPIP_SCALE_IDS]\n",
        "\n",
        "\n",
        "def subset_by_preambles(input_df, id_fragments):\n",
        "  \"\"\"Subsets data by a given list of item preamble fragments.\"\"\"\n",
        "  preambles = []\n",
        "\n",
        "  for id_fragment in id_fragments:\n",
        "    preambles.append(subset_one_preamble(input_df, id_fragment))\n",
        "\n",
        "  return pd.concat(preambles, keys=id_fragments)\n",
        "\n",
        "\n",
        "def describe_by_preambles(input_df, id_fragments,\n",
        "                          by: Union[str, List[str]] = ['median', 'min', 'max', 'std']):\n",
        "  # organize data by preamble_id fragment\n",
        "  df_by_preambles = subset_by_preambles(input_df, id_fragments)\n",
        "\n",
        "  # group by preamble_id fragments\n",
        "  df_grouped = df_by_preambles.groupby(level=0)\n",
        "\n",
        "  # aggregate by specified summary stats\n",
        "  summary = df_grouped.agg(by)\n",
        "\n",
        "  return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gkn2MXkAKDJV",
      "metadata": {
        "id": "Gkn2MXkAKDJV"
      },
      "source": [
        "##Plot for Concurrent Shaping\n",
        "The code below reads in all the scored dataframes for all the models to be compared. Each row of the ridgeplot corresponds to a specific model's score distribution, and each column represents a specific personality dimension. The variable `MODEL_NAMES` contains the names of the models that are compared and that will be rendered on the plot for each row. The variable `models` is a list of tuples, where the first entry in the tuple is a model id (used later on in the code) and the second entry is the path to the scored df in the local filesystem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-dOazCXYKHo2",
      "metadata": {
        "id": "-dOazCXYKHo2"
      },
      "outputs": [],
      "source": [
        "#@markdown Update MODEL_NAMES and models vars based on your models being compared.\n",
        "MODEL_NAMES = ['Llama 2 7B', 'Llama 2 13B', 'Mistral 7B', 'Mixtral 8x7B', 'GPT 3.5 Turbo', 'GPT 4o mini', 'GPT 4o']\n",
        "models = [('ll_7b', 'results_abl03-ds_Llama-2-7b-chat-hf_combined.pkl.scored_df'),\n",
        "          ('ll_13b', 'results_abl03-ds_Llama-2-13b-chat-hf_combined.pkl.scored_df'),\n",
        "          ('mistral_7b', 'results_abl03-dp-Mistral-7B-Instruct-v0.1_combined.pkl.scored_df'),\n",
        "          ('mixtral_8x7b', 'results_abl03-dp-Mixtral-8x7B-Instruct-v0.1_combined.pkl.scored_df'),\n",
        "          ('gpt_35turbo', 'results_abl03-sf_gpt-3.5-turbo-0125_combined.pkl.scored_df'),\n",
        "          ('gpt_4omini', 'results_abl03-dp_gpt-4o-mini_combined.pkl.scored_df'),\n",
        "          ('gpt_4o', 'results_abl03-dp_gpt-4o_combined.pkl.scored_df')]\n",
        "all_df = []\n",
        "for (model_id, drive_filepath) in models:\n",
        "  df = pd.read_pickle(drive_filepath)\n",
        "  df['model_id'] = model_id\n",
        "  all_df.append(df)\n",
        "\n",
        "PLOT_SPACE = np.linspace(1., 5.1)\n",
        "PLOT_COLUMNS = ['IPIP-NEO EXT', 'IPIP-NEO AGR', 'IPIP-NEO CON', 'IPIP-NEO NEU', 'IPIP-NEO OPE']\n",
        "\n",
        "fig = make_subplots(rows=len(MODEL_NAMES), cols=len(PLOT_COLUMNS),\n",
        "                    shared_xaxes=True, shared_yaxes=True,\n",
        "                    column_titles=PLOT_COLUMNS,\n",
        "                    row_titles=MODEL_NAMES,\n",
        "                    x_title='Observed Personality Scores',\n",
        "                    y_title='Frequency Distribution of Response Scores',\n",
        "                    vertical_spacing=0.02, horizontal_spacing=0.01)\n",
        "big5_domain_lvls = get_big5_lvl_fragments()\n",
        "\n",
        "ALL_TRAITS = OrderedDict({\n",
        "    'ext': 'IPIP300-EXT',\n",
        "    'neu': 'IPIP300-NEU',\n",
        "    'ope': 'IPIP300-OPE',\n",
        "    'agr': 'IPIP300-AGR',\n",
        "    'con': 'IPIP300-CON',\n",
        "})\n",
        "\n",
        "for row, df in enumerate(all_df):\n",
        "  for col, (trait, plot_col) in enumerate(ALL_TRAITS.items()):\n",
        "    for i, l in enumerate([1, 9]):\n",
        "      level = f'{trait}{l}'\n",
        "      sub_df = df[df.item_preamble_id.str.contains(level)]\n",
        "      dist_to_plot = sub_df[plot_col]\n",
        "      counts, bins, _ = scipy.stats.binned_statistic(dist_to_plot.values, values=None, statistic='count', bins=PLOT_SPACE, range=(1., 5.1))\n",
        "      scatter_plot = go.Scatter(\n",
        "          x=np.concatenate([np.array([1.]), bins]),\n",
        "          y=np.concatenate([np.array([1.]), counts]),\n",
        "          name=['Prompted Extremely Low', 'Prompted Extremely High'][i],\n",
        "          line=dict(color=['red', 'blue'][i]),\n",
        "          fill='toself',\n",
        "          mode='lines+text')\n",
        "      fig.add_trace(scatter_plot, row=row+1, col=col+1)\n",
        "\n",
        "fig.update_layout(width=1024, height=2048, showlegend=True)\n",
        "fig.update_yaxes(title='', visible=True, showticklabels=False)\n",
        "\n",
        "\n",
        "yaxis_labels = ['yaxis', 'yaxis6', 'yaxis11', 'yaxis16', 'yaxis21', 'yaxis26', 'yaxis31', 'yaxis36', 'yaxis41', 'yaxis46', 'yaxis51', 'yaxis56']\n",
        "for axis_id in yaxis_labels[:len(models)]:\n",
        "  fig['layout'][axis_id].update({\n",
        "      'showticklabels': True, 'visible': True,\n",
        "      'tickmode': 'array',\n",
        "      'tickfont': dict(size=16)\n",
        "  })\n",
        "for axis_id in ['xaxis16', 'xaxis17', 'xaxis18', 'xaxis19', 'xaxis20']:\n",
        "  fig['layout'][axis_id].update({\n",
        "      'tickfont': dict(size=16)\n",
        "  })\n",
        "for fig_legend in fig['data'][2:]:\n",
        "  fig_legend['showlegend'] = False\n",
        "fig.update_layout(title_x=0.5)\n",
        "fig.update_layout(legend=dict(\n",
        "    orientation='h',\n",
        "    yanchor='bottom',\n",
        "    y=1.03,\n",
        "    xanchor='right',\n",
        "    x=1,\n",
        "    font=dict(size=22)\n",
        "))\n",
        "fig.for_each_annotation(lambda a: a.update(font=dict(size=(22 if a['textangle'] != 90 else 16))))\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1ocQdqlUJ5ER1T88O0_c4OJdYp2W3tB1H",
          "timestamp": 1688586959757
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
