{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "IQ0qR8rhOITR",
      "metadata": {
        "id": "IQ0qR8rhOITR"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "This colab contains code used to run the ridgeplot visualization for the Independent Trait Shaping experiments on the various LLMs experimented on in the paper \"Personality Traits in Large Language Models\" (https://arxiv.org/pdf/2307.00184). The code assumes that all the data produced and consumed in the colab (especially the pickled dataframe outputs of running inference on various LLMs) lives in a local filesystem either in a cloud instance running a Jupyter notebook such as Google Colab or a desktop. But those file I/O operations can easily be replaced to use any other file management solutions. The inline comments for some of the operations explain the motivation behind them and what to expect in the results of running an analysis in a cell.\n",
        "\n",
        "To run this colab:\n",
        "1. Connect to an appropriate runtime. (For instance, if running the bulk inference directly from the colab, connect to a GPU kernel.)\n",
        "2. Check experiment parameters below.\n",
        "3. Run the code cells for visualizations.\n",
        "\n",
        "NOTE: Make sure to store and run this notebook from a location where the Psyborgs codebase package is stored (personality_in_llms.psyborgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E6reGimEOU25",
      "metadata": {
        "id": "E6reGimEOU25"
      },
      "source": [
        "# Setup\n",
        "The repo containing this notebook has a version of the Psyborgs codebase needed to make the notebook run. But in case a more recent version is needed, it can be fetched from https://github.com/google-research/google-research/tree/master/psyborgs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q7h-4OU5ZJZd",
      "metadata": {
        "id": "q7h-4OU5ZJZd"
      },
      "source": [
        "### Install Psyborgs Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IZ5zCEVAGeMo",
      "metadata": {
        "id": "IZ5zCEVAGeMo"
      },
      "outputs": [],
      "source": [
        "#@markdown Run this cell to install the dependencies needed to run Psyborgs.\n",
        "#@markdown The dependencies are in a requirements.txt file in the Psyborgs repo.\n",
        "%pip install -r personality_in_llms/psyborgs/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sSHjdIg7HZ6P",
      "metadata": {
        "id": "sSHjdIg7HZ6P"
      },
      "outputs": [],
      "source": [
        "#@title Load Libraries\n",
        "#@markdown Run this cell to import dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from psyborgs import score_calculation\n",
        "from psyborgs import survey_bench_lib\n",
        "\n",
        "# dependencies for descriptive statistics\n",
        "import itertools\n",
        "from typing import Union, List\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vp2caJdAGy3s",
      "metadata": {
        "id": "vp2caJdAGy3s"
      },
      "outputs": [],
      "source": [
        "#@title File locations setup  { run: \"auto\" }\n",
        "\n",
        "#@markdown `PKL_PATH` is the filename of pickled results to be analyzed.\n",
        "#@markdown This is the output dataframes from the LLM inference runs packaged in pkl format.\n",
        "#@markdown This is the input for this colab.\n",
        "PKL_PATH = 'sample_pkl_file.pkl'  # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown `ADMIN_SESSION_PATH` is the file path of the input admin session that the experiment is based on.\n",
        "ADMIN_SESSION_PATH = 'admin_sessions/sample_admin_session.json'  # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown Path of the file where the joined test scores pickled dataframe should be stored.\n",
        "SAVE_SCORES_FILENAME = 'sample_scored_dataframe.pkl'  # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown Whether the model who's data is being analyzed is a PaLM model variant or not?\n",
        "#@markdown Some of the pre-processing on the input dataframe differs between PaLM and non-PaLM models.\n",
        "IS_PALM_MODEL = True  # @param {\"type\":\"boolean\"}\n",
        "\n",
        "#@markdown This is a model identifier needed for Psyborgs code. More info here: psyborgs/survey_bench_lib.py:L63\n",
        "MODEL_ID = 'PaLM'  #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afcf46d8",
      "metadata": {
        "id": "afcf46d8"
      },
      "outputs": [],
      "source": [
        "SPID = ['item_preamble_id',\n",
        "        'item_postamble_id',\n",
        "        'response_scale_id',\n",
        "        'response_choice_postamble_id',\n",
        "        'model_id']\n",
        "\n",
        "BFI_SCALE_IDS = ['BFI-EXT', 'BFI-AGR', 'BFI-CON', 'BFI-NEU', 'BFI-OPE']\n",
        "IPIP_SCALE_IDS = ['IPIP300-EXT', 'IPIP300-AGR', 'IPIP300-CON', 'IPIP300-NEU', 'IPIP300-OPE']\n",
        "VALIDATION_SCALE_IDS = ['PA', 'NA', 'CSE', 'CPI', 'PHYS', 'VRBL', 'ANGR', 'HSTL', 'ACHV', 'CONF', 'SCRT']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b33bced",
      "metadata": {
        "id": "5b33bced"
      },
      "source": [
        "## Unpickle Raw Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddb7f9a",
      "metadata": {
        "id": "8ddb7f9a"
      },
      "outputs": [],
      "source": [
        "df_raw_response_scores = pd.read_pickle(PKL_PATH)\n",
        "\n",
        "# if PaLM model inference was used, convert from byte to string\n",
        "if IS_PALM_MODEL:\n",
        "  for col, dtype in df_raw_response_scores.dtypes.items():\n",
        "    if dtype == object:  # Only process byte object columns.\n",
        "      df_raw_response_scores[col] = df_raw_response_scores[col].apply(lambda x: x.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70799c2c",
      "metadata": {
        "id": "70799c2c"
      },
      "outputs": [],
      "source": [
        "df_raw_response_scores.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8740e498",
      "metadata": {
        "id": "8740e498"
      },
      "outputs": [],
      "source": [
        "test_df = df_raw_response_scores.query(\n",
        "    \"item_postamble_id == 'plk-ipip-0' \u0026 item_preamble_id == 'ext0-agr2-con0-neu0-ope0-d36-ev2' \u0026 item_id == 'ipip1'\"\n",
        ")\n",
        "\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413d0326",
      "metadata": {
        "id": "413d0326"
      },
      "source": [
        "## Load Admin Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de1538b",
      "metadata": {
        "id": "1de1538b"
      },
      "outputs": [],
      "source": [
        "admin_session = survey_bench_lib.load_admin_session(\n",
        "    ADMIN_SESSION_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae3ff445",
      "metadata": {
        "id": "ae3ff445"
      },
      "source": [
        "# Score Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58248998",
      "metadata": {
        "id": "58248998"
      },
      "outputs": [],
      "source": [
        "if not IS_PALM_MODEL:\n",
        "  # adapt df to match a df with scores for possible continuations\n",
        "  df_raw_response_scores['score'] = 1\n",
        "  df_raw_response_scores['response_value'] = df_raw_response_scores['model_output'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4225ed4",
      "metadata": {
        "id": "f4225ed4"
      },
      "outputs": [],
      "source": [
        "# score session\n",
        "scored_session_df = score_calculation.score_session(\n",
        "    admin_session, df_raw_response_scores)\n",
        "\n",
        "scored_session_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a850a3c-f8ed-4b86-a95a-37c6c1d24803",
      "metadata": {
        "id": "4a850a3c-f8ed-4b86-a95a-37c6c1d24803"
      },
      "outputs": [],
      "source": [
        "# optional: save scores to disk\n",
        "if SAVE_SCORES_FILENAME:\n",
        "  scored_session_df.to_pickle(SAVE_SCORES_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caz5fIVr-5Di",
      "metadata": {
        "id": "caz5fIVr-5Di"
      },
      "source": [
        "# Ridgeplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913ab311",
      "metadata": {
        "id": "913ab311"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.float_format', '{:.2f}'.format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c924f8b",
      "metadata": {
        "id": "3c924f8b"
      },
      "outputs": [],
      "source": [
        "def get_domain_fragments(big5_id, levels=range(1, 10)):\n",
        "  \"\"\"Returns list of preamble ID fragments for one domain.\"\"\"\n",
        "  return [f'{big5_id}{i}' for i in levels]\n",
        "\n",
        "\n",
        "def get_big5_lvl_fragments(levels=range(1, 10)):\n",
        "  \"\"\"Returns list of preamble ID fragments for all Big Five domains.\"\"\"\n",
        "  big5_id_fragments = ['ext', 'agr', 'con', 'neu', 'ope']\n",
        "  nested_fragments = [get_domain_fragments(big5_id, levels) for big5_id in big5_id_fragments]\n",
        "  preamble_id_fragments = list(itertools.chain(*nested_fragments))\n",
        "  return preamble_id_fragments\n",
        "\n",
        "\n",
        "def subset_one_preamble(df, id_fragment):\n",
        "  return df[df['item_preamble_id'].str.contains(id_fragment)][IPIP_SCALE_IDS]\n",
        "\n",
        "\n",
        "def subset_by_preambles(df, id_fragments):\n",
        "  \"\"\"Subsets data by a given list of item preamble fragments.\"\"\"\n",
        "  preambles = []\n",
        "\n",
        "  for id_fragment in id_fragments:\n",
        "    preambles.append(subset_one_preamble(df, id_fragment))\n",
        "\n",
        "  return pd.concat(preambles, keys=id_fragments)\n",
        "\n",
        "\n",
        "def describe_by_preambles(df,\n",
        "                          id_fragments,\n",
        "                          by: Union[str, List[str]] = ['median', 'min', 'max', 'std']):\n",
        "  \"\"\"Describe dataframe using summary statistics grouping by preambles.\"\"\"\n",
        "  # organize data by preamble_id fragment\n",
        "  df_by_preambles = subset_by_preambles(df, id_fragments)\n",
        "\n",
        "  # group by preamble_id fragments\n",
        "  df_grouped = df_by_preambles.groupby(level=0)\n",
        "\n",
        "  # aggregate by specified summary stats\n",
        "  summary = df_grouped.agg(by)\n",
        "\n",
        "  return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MJktVCsFKrqV",
      "metadata": {
        "id": "MJktVCsFKrqV"
      },
      "outputs": [],
      "source": [
        "PLOT_SPACE = np.linspace(1., 5.1)\n",
        "PLOT_COLUMNS = ['IPIP300-EXT', 'IPIP300-AGR', 'IPIP300-CON', 'IPIP300-NEU', 'IPIP300-OPE']\n",
        "EXT_COUNT = 10\n",
        "\n",
        "DIMENSION_PREFIXES = ['ext', 'agr', 'con', 'neu', 'ope']\n",
        "\n",
        "fig = make_subplots(rows=5, cols=len(PLOT_COLUMNS),\n",
        "                    shared_xaxes=True, shared_yaxes=True,\n",
        "                    column_titles=['IPIP-NEO EXT', 'IPIP-NEO AGR', 'IPIP-NEO CON', 'IPIP-NEO NEU', 'IPIP-NEO OPE'],\n",
        "                    row_titles=['Prompted EXT', 'Prompted AGR', 'Prompted CON', 'Prompted NEU', 'Prompted OPE'],\n",
        "                    x_title='Observed Personality Scores',\n",
        "                    vertical_spacing=0.01, horizontal_spacing=0.01)\n",
        "big5_domain_lvls = get_big5_lvl_fragments()\n",
        "sub_pre_df = subset_by_preambles(scored_session_df, big5_domain_lvls)\n",
        "\n",
        "y_ticks_coordinates = []\n",
        "\n",
        "for p, prefix in enumerate(DIMENSION_PREFIXES):\n",
        "  for i, (ext_id, sub_df) in enumerate(sub_pre_df.groupby(level=0)):\n",
        "    if prefix not in ext_id: continue\n",
        "    for j, plot_col in enumerate(PLOT_COLUMNS):\n",
        "      dist_to_plot = sub_df[plot_col]\n",
        "      counts, bins, _ = scipy.stats.binned_statistic(dist_to_plot.values, values=None, statistic='count', bins=PLOT_SPACE, range=(1., 5.1))\n",
        "\n",
        "      scatter_plot = go.Scatter(\n",
        "          x=np.concatenate([np.array([1.]), bins]),\n",
        "          y=np.concatenate([np.array([i*5.]), counts + i*5]),\n",
        "          fill='toself',\n",
        "          mode='lines+text')\n",
        "\n",
        "\n",
        "      fig.add_trace(scatter_plot, row=p+1, col=j+1)\n",
        "\n",
        "    y_ticks_coordinates.append(scatter_plot.y.min())\n",
        "\n",
        "fig.update_layout(width=1024, height=1024, showlegend=False)\n",
        "\n",
        "y_ticks_coordinates = out = [y_ticks_coordinates[i: i+9] for i in range(0, len(y_ticks_coordinates), 9)]\n",
        "y_ticks = [\n",
        "    ('yaxis', 'ext', y_ticks_coordinates[0]),\n",
        "    ('yaxis6', 'agr', y_ticks_coordinates[1]),\n",
        "    ('yaxis11', 'con', y_ticks_coordinates[2]),\n",
        "    ('yaxis16', 'neu', y_ticks_coordinates[3]),\n",
        "    ('yaxis21', 'ope', y_ticks_coordinates[4]),\n",
        "]\n",
        "\n",
        "for axis_id in ['xaxis21', 'xaxis22', 'xaxis23', 'xaxis24', 'xaxis25']:\n",
        "  fig['layout'][axis_id].update({\n",
        "      'tickfont': dict(size=16)\n",
        "  })\n",
        "\n",
        "for axis_id, tick_id, coordinates in y_ticks:\n",
        "  fig['layout'][axis_id].update({\n",
        "      'showticklabels': True, 'visible': True,\n",
        "      'tickmode': 'array',\n",
        "      'tickvals': coordinates,\n",
        "      'ticktext': ['1', '', '3', '', '5', '', '7', '', '9'],\n",
        "      'tickfont': dict(size=16)\n",
        "  })\n",
        "\n",
        "fig.for_each_annotation(lambda a: a.update(font=dict(size=(22 if a['textangle'] != 90 else 20))))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S1njVy2KxeiE",
      "metadata": {
        "id": "S1njVy2KxeiE"
      },
      "outputs": [],
      "source": [
        "def plot_ridge(prefix, title, axis_label):\n",
        "  f = make_subplots(rows=1, cols=len(PLOT_COLUMNS),\n",
        "                    shared_xaxes=True, shared_yaxes=True,\n",
        "                    column_titles=PLOT_COLUMNS,\n",
        "                    row_titles=[axis_label])\n",
        "  sub_pre_df = subset_by_preambles(scored_session_df, big5_domain_lvls)\n",
        "  for i, (ext_id, sub_df) in enumerate(sub_pre_df.groupby(level=0)):\n",
        "    if prefix not in ext_id: continue\n",
        "    for j, plot_col in enumerate(PLOT_COLUMNS):\n",
        "      dist_to_plot = sub_df[plot_col]\n",
        "      counts, bins, _ = scipy.stats.binned_statistic(dist_to_plot.values, values=None, statistic='count', bins=PLOT_SPACE, range=(1., 5.1))\n",
        "\n",
        "      plot = go.Scatter(\n",
        "          x=bins,\n",
        "          y=counts + i*5,\n",
        "          fill='toself',\n",
        "          mode='lines')\n",
        "\n",
        "      f.add_trace(plot, row=1, col=j+1)\n",
        "\n",
        "  f.update_layout(width=800, height=400, showlegend=False, title=title)\n",
        "\n",
        "  f.update_layout(\n",
        "      yaxis=dict(\n",
        "          nticks=EXT_COUNT,\n",
        "          tickmode='array',\n",
        "          tickvals=[i*15 for i in range(EXT_COUNT)],\n",
        "          ticktext=[i for i in range(EXT_COUNT)]\n",
        "      )\n",
        "  )\n",
        "\n",
        "  f.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fd4Ftw31ZCbB",
      "metadata": {
        "id": "Fd4Ftw31ZCbB"
      },
      "outputs": [],
      "source": [
        "plot_ridge(DIMENSION_PREFIXES[0], title='Distribution of response scores when increasing levels of extroversion', axis_label='Extroversion level')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JjECF73B9zVz",
      "metadata": {
        "id": "JjECF73B9zVz"
      },
      "outputs": [],
      "source": [
        "plot_ridge(DIMENSION_PREFIXES[1], title='Distribution of response scores when increasing levels of agreeableness', axis_label='Agreeableness level')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eKxkUkUU93t9",
      "metadata": {
        "id": "eKxkUkUU93t9"
      },
      "outputs": [],
      "source": [
        "plot_ridge(DIMENSION_PREFIXES[2], title='Distribution of response scores when increasing levels of conscientiousness', axis_label='Conscientiousness level')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6n2zrG97Ns",
      "metadata": {
        "id": "ad6n2zrG97Ns"
      },
      "outputs": [],
      "source": [
        "plot_ridge(DIMENSION_PREFIXES[3], title='Distribution of response scores when increasing levels of neuroticism', axis_label='Neuroticism level')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ToQUGqW9-uU",
      "metadata": {
        "id": "4ToQUGqW9-uU"
      },
      "outputs": [],
      "source": [
        "plot_ridge(DIMENSION_PREFIXES[4], title='Distribution of response scores when increasing levels of openness', axis_label='Openness level')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Independent_Trait_Shaping_Viz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
